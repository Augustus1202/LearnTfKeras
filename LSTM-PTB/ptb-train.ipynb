{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model with PTB in tf.Keras\n",
    "In this project, I'm trying to build language model using PTB dataset. \n",
    "\n",
    "The code is modified from [CharlesWu123/SelfStudyTF](git@github.com:CharlesWu123/SelfStudyTF.git)\n",
    "\n",
    "I'm trying to use tf.Keras as possible.\n",
    "\n",
    "The data preprocessing is omitted in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "from tensorflow import keras\n",
    "\n",
    "TRAIN_DATA = './ptb.train'\n",
    "EVAL_DATA = './ptb.valid'\n",
    "TEST_DATA = './ptb.test'\n",
    "VOCAB = './ptb.vocab'          # Vocabulary file\n",
    "HIDDEN_SIZE = 300\n",
    "NUM_LAYERS = 2\n",
    "VOCAB_SIZE = 10000\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TRAIN_NUM_STEP = 30\n",
    "\n",
    "EVAL_BATCH_SIZE = 1\n",
    "EVAL_NUM_STEP = 1\n",
    "NUM_EPOCH = 50\n",
    "LSTM_KEEP_PROB = 0.9\n",
    "EMBEDDING_KEEP_PROB = 0.9\n",
    "MAX_GRAD_NORM = 5\n",
    "SHARE_EMB_AND_SOFTMAX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid 'Blas GEMM launch failed'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from file\n",
    "After preprocessing, the data in file is the ids of words according to vocabulary file.\n",
    "\n",
    "Each line is ended by &lt;eos>, and missing words has been replaced by &lt;unk>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length 929589\n",
      "Validating data length 73760\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_file):\n",
    "    with open(data_file, 'r') as fin:\n",
    "        # read full file as a long string\n",
    "        id_string = ' '.join([line.strip() for line in fin.readlines()])\n",
    "    id_list = [int(w) for w in id_string.split()]  # Convert word id to integer\n",
    "    return id_list\n",
    "\n",
    "\n",
    "# Load data from file\n",
    "data_train = load_data(TRAIN_DATA)\n",
    "data_val = load_data(EVAL_DATA)\n",
    "\n",
    "len_train = len(data_train)\n",
    "len_val = len(data_val)\n",
    "\n",
    "print('Training data length', len_train)\n",
    "print('Validating data length', len_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input data generator\n",
    "Design a generator to generate input data for training.\n",
    "Shift the input data right with one word for labeling.\n",
    "As for sparse_categorical_accuracy, the labels should be reshaped for one more dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=5):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "        # skip_step is the number of words which will be skipped before the next\n",
    "        # batch is skimmed from the data set\n",
    "        self.skip_step = skip_step\n",
    "\n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.num_steps))\n",
    "        y = np.zeros((self.batch_size, self.num_steps))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    # reset the index back to the start of the data set\n",
    "                    self.current_idx = 0\n",
    "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                temp_y = self.data[self.current_idx +\n",
    "                                   1:self.current_idx + self.num_steps + 1]\n",
    "                # convert all of temp_y into a one hot representation\n",
    "                y[i, :] = temp_y\n",
    "                self.current_idx += self.skip_step\n",
    "            # x = x.reshape(self.batch_size, self.num_steps, 1)\n",
    "            py = y.reshape(self.batch_size, self.num_steps, 1)\n",
    "            yield x, py\n",
    "\n",
    "gen_train_data = KerasBatchGenerator(\n",
    "    data_train, TRAIN_NUM_STEP, TRAIN_BATCH_SIZE, VOCAB_SIZE,\n",
    "    skip_step=TRAIN_NUM_STEP\n",
    ")\n",
    "\n",
    "gen_val_data = KerasBatchGenerator(\n",
    "    data_val, TRAIN_NUM_STEP, TRAIN_BATCH_SIZE, VOCAB_SIZE,\n",
    "    skip_step=TRAIN_NUM_STEP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "Here we build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0925 15:11:56.121625 10056 deprecation.py:506] From C:\\Users\\HP\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0925 15:11:56.159556 10056 deprecation.py:506] From C:\\Users\\HP\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 30, 300)           722400    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 30, 300)           722400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 30, 10000)         3010000   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 10000)         0         \n",
      "=================================================================\n",
      "Total params: 7,454,800\n",
      "Trainable params: 7,454,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(VOCAB_SIZE, HIDDEN_SIZE, input_length=TRAIN_NUM_STEP))\n",
    "model.add(keras.layers.Dropout(1 - EMBEDDING_KEEP_PROB))\n",
    "for _ in range(NUM_LAYERS):\n",
    "    model.add(keras.layers.CuDNNLSTM(units=HIDDEN_SIZE, return_sequences=True))\n",
    "model.add(keras.layers.Dropout(1 - LSTM_KEEP_PROB))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(VOCAB_SIZE)))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train\n",
    "Store checkpoint along training.\n",
    "\n",
    "Using tensorflow to track the running status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 15:11:57.257587 10056 deprecation.py:323] From C:\\Users\\HP\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.8378 - sparse_categorical_accuracy: 0.0493\n",
      "Epoch 00001: saving model to ./models/model-01.hdf5\n",
      "242/242 [==============================] - 70s 290ms/step - loss: 6.8374 - sparse_categorical_accuracy: 0.0493 - val_loss: 6.6384 - val_sparse_categorical_accuracy: 0.0458\n",
      "Epoch 2/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.6589 - sparse_categorical_accuracy: 0.0501\n",
      "Epoch 00002: saving model to ./models/model-02.hdf5\n",
      "242/242 [==============================] - 62s 255ms/step - loss: 6.6590 - sparse_categorical_accuracy: 0.0502 - val_loss: 6.6530 - val_sparse_categorical_accuracy: 0.0478\n",
      "Epoch 3/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.6524 - sparse_categorical_accuracy: 0.0498\n",
      "Epoch 00003: saving model to ./models/model-03.hdf5\n",
      "242/242 [==============================] - 57s 234ms/step - loss: 6.6527 - sparse_categorical_accuracy: 0.0499 - val_loss: 6.6258 - val_sparse_categorical_accuracy: 0.0476\n",
      "Epoch 4/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.6516 - sparse_categorical_accuracy: 0.0494\n",
      "Epoch 00004: saving model to ./models/model-04.hdf5\n",
      "242/242 [==============================] - 58s 240ms/step - loss: 6.6520 - sparse_categorical_accuracy: 0.0495 - val_loss: 6.6252 - val_sparse_categorical_accuracy: 0.0488\n",
      "Epoch 5/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.6479 - sparse_categorical_accuracy: 0.0503\n",
      "Epoch 00005: saving model to ./models/model-05.hdf5\n",
      "242/242 [==============================] - 61s 251ms/step - loss: 6.6485 - sparse_categorical_accuracy: 0.0504 - val_loss: 6.6447 - val_sparse_categorical_accuracy: 0.0469\n",
      "Epoch 6/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.6129 - sparse_categorical_accuracy: 0.0644\n",
      "Epoch 00006: saving model to ./models/model-06.hdf5\n",
      "242/242 [==============================] - 59s 242ms/step - loss: 6.6131 - sparse_categorical_accuracy: 0.0645 - val_loss: 6.5435 - val_sparse_categorical_accuracy: 0.0794\n",
      "Epoch 7/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.5459 - sparse_categorical_accuracy: 0.0728- ETA: 0s - loss: 6.5464 - sparse_categorical_accurac\n",
      "Epoch 00007: saving model to ./models/model-07.hdf5\n",
      "242/242 [==============================] - 60s 247ms/step - loss: 6.5461 - sparse_categorical_accuracy: 0.0729 - val_loss: 6.5027 - val_sparse_categorical_accuracy: 0.0787\n",
      "Epoch 8/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.5076 - sparse_categorical_accuracy: 0.0756\n",
      "Epoch 00008: saving model to ./models/model-08.hdf5\n",
      "242/242 [==============================] - 61s 251ms/step - loss: 6.5078 - sparse_categorical_accuracy: 0.0757 - val_loss: 6.4596 - val_sparse_categorical_accuracy: 0.0792\n",
      "Epoch 9/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.4558 - sparse_categorical_accuracy: 0.0817\n",
      "Epoch 00009: saving model to ./models/model-09.hdf5\n",
      "242/242 [==============================] - 59s 243ms/step - loss: 6.4561 - sparse_categorical_accuracy: 0.0818 - val_loss: 6.4264 - val_sparse_categorical_accuracy: 0.0878\n",
      "Epoch 10/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.4030 - sparse_categorical_accuracy: 0.0917\n",
      "Epoch 00010: saving model to ./models/model-10.hdf5\n",
      "242/242 [==============================] - 61s 251ms/step - loss: 6.4033 - sparse_categorical_accuracy: 0.0917 - val_loss: 6.3542 - val_sparse_categorical_accuracy: 0.0994\n",
      "Epoch 11/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.3324 - sparse_categorical_accuracy: 0.0970\n",
      "Epoch 00011: saving model to ./models/model-11.hdf5\n",
      "242/242 [==============================] - 60s 249ms/step - loss: 6.3326 - sparse_categorical_accuracy: 0.0970 - val_loss: 6.2803 - val_sparse_categorical_accuracy: 0.1040\n",
      "Epoch 12/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.2470 - sparse_categorical_accuracy: 0.1046\n",
      "Epoch 00012: saving model to ./models/model-12.hdf5\n",
      "242/242 [==============================] - 59s 245ms/step - loss: 6.2470 - sparse_categorical_accuracy: 0.1046 - val_loss: 6.1696 - val_sparse_categorical_accuracy: 0.1088\n",
      "Epoch 13/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 6.1158 - sparse_categorical_accuracy: 0.1258\n",
      "Epoch 00013: saving model to ./models/model-13.hdf5\n",
      "242/242 [==============================] - 63s 261ms/step - loss: 6.1158 - sparse_categorical_accuracy: 0.1258 - val_loss: 6.0535 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 14/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.9901 - sparse_categorical_accuracy: 0.1443\n",
      "Epoch 00014: saving model to ./models/model-14.hdf5\n",
      "242/242 [==============================] - 63s 262ms/step - loss: 5.9900 - sparse_categorical_accuracy: 0.1442 - val_loss: 5.8598 - val_sparse_categorical_accuracy: 0.1549\n",
      "Epoch 15/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.8358 - sparse_categorical_accuracy: 0.1583\n",
      "Epoch 00015: saving model to ./models/model-15.hdf5\n",
      "242/242 [==============================] - 63s 259ms/step - loss: 5.8357 - sparse_categorical_accuracy: 0.1582 - val_loss: 5.7611 - val_sparse_categorical_accuracy: 0.1625\n",
      "Epoch 16/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.7030 - sparse_categorical_accuracy: 0.1671\n",
      "Epoch 00016: saving model to ./models/model-16.hdf5\n",
      "242/242 [==============================] - 59s 246ms/step - loss: 5.7028 - sparse_categorical_accuracy: 0.1671 - val_loss: 5.6548 - val_sparse_categorical_accuracy: 0.1689\n",
      "Epoch 17/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.6387 - sparse_categorical_accuracy: 0.1715\n",
      "Epoch 00017: saving model to ./models/model-17.hdf5\n",
      "242/242 [==============================] - 63s 260ms/step - loss: 5.6380 - sparse_categorical_accuracy: 0.1715 - val_loss: 5.6009 - val_sparse_categorical_accuracy: 0.1721\n",
      "Epoch 18/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.5620 - sparse_categorical_accuracy: 0.1766\n",
      "Epoch 00018: saving model to ./models/model-18.hdf5\n",
      "242/242 [==============================] - 63s 258ms/step - loss: 5.5610 - sparse_categorical_accuracy: 0.1766 - val_loss: 5.5145 - val_sparse_categorical_accuracy: 0.1792\n",
      "Epoch 19/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.4777 - sparse_categorical_accuracy: 0.1820\n",
      "Epoch 00019: saving model to ./models/model-19.hdf5\n",
      "242/242 [==============================] - 62s 256ms/step - loss: 5.4768 - sparse_categorical_accuracy: 0.1820 - val_loss: 5.4379 - val_sparse_categorical_accuracy: 0.1847\n",
      "Epoch 20/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.3779 - sparse_categorical_accuracy: 0.1883\n",
      "Epoch 00020: saving model to ./models/model-20.hdf5\n",
      "242/242 [==============================] - 62s 256ms/step - loss: 5.3771 - sparse_categorical_accuracy: 0.1883 - val_loss: 5.4250 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 21/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.3633 - sparse_categorical_accuracy: 0.1894\n",
      "Epoch 00021: saving model to ./models/model-21.hdf5\n",
      "242/242 [==============================] - 62s 254ms/step - loss: 5.3621 - sparse_categorical_accuracy: 0.1894 - val_loss: 5.4147 - val_sparse_categorical_accuracy: 0.1881\n",
      "Epoch 22/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.3074 - sparse_categorical_accuracy: 0.1934\n",
      "Epoch 00022: saving model to ./models/model-22.hdf5\n",
      "242/242 [==============================] - 64s 266ms/step - loss: 5.3063 - sparse_categorical_accuracy: 0.1934 - val_loss: 5.4468 - val_sparse_categorical_accuracy: 0.1885\n",
      "Epoch 23/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.1917 - sparse_categorical_accuracy: 0.2016\n",
      "Epoch 00023: saving model to ./models/model-23.hdf5\n",
      "242/242 [==============================] - 71s 291ms/step - loss: 5.1908 - sparse_categorical_accuracy: 0.2016 - val_loss: 5.3350 - val_sparse_categorical_accuracy: 0.1951\n",
      "Epoch 24/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.1500 - sparse_categorical_accuracy: 0.2047\n",
      "Epoch 00024: saving model to ./models/model-24.hdf5\n",
      "242/242 [==============================] - 65s 268ms/step - loss: 5.1490 - sparse_categorical_accuracy: 0.2047 - val_loss: 5.2778 - val_sparse_categorical_accuracy: 0.2012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.0913 - sparse_categorical_accuracy: 0.2086\n",
      "Epoch 00025: saving model to ./models/model-25.hdf5\n",
      "242/242 [==============================] - 63s 262ms/step - loss: 5.0904 - sparse_categorical_accuracy: 0.2086 - val_loss: 5.2455 - val_sparse_categorical_accuracy: 0.2038\n",
      "Epoch 26/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.0561 - sparse_categorical_accuracy: 0.2112\n",
      "Epoch 00026: saving model to ./models/model-26.hdf5\n",
      "242/242 [==============================] - 63s 260ms/step - loss: 5.0549 - sparse_categorical_accuracy: 0.2112 - val_loss: 5.4289 - val_sparse_categorical_accuracy: 0.1929\n",
      "Epoch 27/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.0520 - sparse_categorical_accuracy: 0.2118\n",
      "Epoch 00027: saving model to ./models/model-27.hdf5\n",
      "242/242 [==============================] - 64s 264ms/step - loss: 5.0507 - sparse_categorical_accuracy: 0.2118 - val_loss: 5.2227 - val_sparse_categorical_accuracy: 0.2071\n",
      "Epoch 28/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 5.0272 - sparse_categorical_accuracy: 0.2131\n",
      "Epoch 00028: saving model to ./models/model-28.hdf5\n",
      "242/242 [==============================] - 65s 269ms/step - loss: 5.0261 - sparse_categorical_accuracy: 0.2131 - val_loss: 5.1600 - val_sparse_categorical_accuracy: 0.2124\n",
      "Epoch 29/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.9254 - sparse_categorical_accuracy: 0.2196\n",
      "Epoch 00029: saving model to ./models/model-29.hdf5\n",
      "242/242 [==============================] - 63s 260ms/step - loss: 4.9247 - sparse_categorical_accuracy: 0.2196 - val_loss: 5.1952 - val_sparse_categorical_accuracy: 0.2098\n",
      "Epoch 30/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.8812 - sparse_categorical_accuracy: 0.2226\n",
      "Epoch 00030: saving model to ./models/model-30.hdf5\n",
      "242/242 [==============================] - 68s 281ms/step - loss: 4.8807 - sparse_categorical_accuracy: 0.2226 - val_loss: 5.1923 - val_sparse_categorical_accuracy: 0.2089\n",
      "Epoch 31/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.8325 - sparse_categorical_accuracy: 0.2258\n",
      "Epoch 00031: saving model to ./models/model-31.hdf5\n",
      "242/242 [==============================] - 63s 261ms/step - loss: 4.8320 - sparse_categorical_accuracy: 0.2258 - val_loss: 5.1441 - val_sparse_categorical_accuracy: 0.2147\n",
      "Epoch 32/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.8185 - sparse_categorical_accuracy: 0.2267\n",
      "Epoch 00032: saving model to ./models/model-32.hdf5\n",
      "242/242 [==============================] - 65s 269ms/step - loss: 4.8180 - sparse_categorical_accuracy: 0.2267 - val_loss: 5.0793 - val_sparse_categorical_accuracy: 0.2201\n",
      "Epoch 33/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.7836 - sparse_categorical_accuracy: 0.2288\n",
      "Epoch 00033: saving model to ./models/model-33.hdf5\n",
      "242/242 [==============================] - 66s 271ms/step - loss: 4.7827 - sparse_categorical_accuracy: 0.2288 - val_loss: 5.1249 - val_sparse_categorical_accuracy: 0.2168\n",
      "Epoch 34/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.7664 - sparse_categorical_accuracy: 0.2302\n",
      "Epoch 00034: saving model to ./models/model-34.hdf5\n",
      "242/242 [==============================] - 64s 266ms/step - loss: 4.7663 - sparse_categorical_accuracy: 0.2302 - val_loss: 5.2207 - val_sparse_categorical_accuracy: 0.2152\n",
      "Epoch 35/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.7133 - sparse_categorical_accuracy: 0.2339\n",
      "Epoch 00035: saving model to ./models/model-35.hdf5\n",
      "242/242 [==============================] - 66s 271ms/step - loss: 4.7130 - sparse_categorical_accuracy: 0.2339 - val_loss: 5.0896 - val_sparse_categorical_accuracy: 0.2204\n",
      "Epoch 36/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.6715 - sparse_categorical_accuracy: 0.2361\n",
      "Epoch 00036: saving model to ./models/model-36.hdf5\n",
      "242/242 [==============================] - 66s 274ms/step - loss: 4.6712 - sparse_categorical_accuracy: 0.2361 - val_loss: 5.1082 - val_sparse_categorical_accuracy: 0.2192\n",
      "Epoch 37/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.6850 - sparse_categorical_accuracy: 0.2351- ETA: 3s - loss: 4.6241 - \n",
      "Epoch 00037: saving model to ./models/model-37.hdf5\n",
      "242/242 [==============================] - 66s 272ms/step - loss: 4.6846 - sparse_categorical_accuracy: 0.2351 - val_loss: 5.1764 - val_sparse_categorical_accuracy: 0.2139\n",
      "Epoch 38/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.6172 - sparse_categorical_accuracy: 0.2396\n",
      "Epoch 00038: saving model to ./models/model-38.hdf5\n",
      "242/242 [==============================] - 65s 268ms/step - loss: 4.6161 - sparse_categorical_accuracy: 0.2396 - val_loss: 5.1080 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 39/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.6318 - sparse_categorical_accuracy: 0.2392\n",
      "Epoch 00039: saving model to ./models/model-39.hdf5\n",
      "242/242 [==============================] - 65s 269ms/step - loss: 4.6316 - sparse_categorical_accuracy: 0.2392 - val_loss: 5.1414 - val_sparse_categorical_accuracy: 0.2177\n",
      "Epoch 40/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.6146 - sparse_categorical_accuracy: 0.2400\n",
      "Epoch 00040: saving model to ./models/model-40.hdf5\n",
      "242/242 [==============================] - 65s 270ms/step - loss: 4.6140 - sparse_categorical_accuracy: 0.2400 - val_loss: 5.1683 - val_sparse_categorical_accuracy: 0.2164\n",
      "Epoch 41/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.5684 - sparse_categorical_accuracy: 0.2431- ETA: 3s - loss: 4.5479 - \n",
      "Epoch 00041: saving model to ./models/model-41.hdf5\n",
      "242/242 [==============================] - 64s 265ms/step - loss: 4.5678 - sparse_categorical_accuracy: 0.2431 - val_loss: 5.1018 - val_sparse_categorical_accuracy: 0.2217\n",
      "Epoch 42/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.5638 - sparse_categorical_accuracy: 0.2430\n",
      "Epoch 00042: saving model to ./models/model-42.hdf5\n",
      "242/242 [==============================] - 65s 268ms/step - loss: 4.5633 - sparse_categorical_accuracy: 0.2430 - val_loss: 5.3499 - val_sparse_categorical_accuracy: 0.2076\n",
      "Epoch 43/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.5145 - sparse_categorical_accuracy: 0.2463\n",
      "Epoch 00043: saving model to ./models/model-43.hdf5\n",
      "242/242 [==============================] - 64s 264ms/step - loss: 4.5141 - sparse_categorical_accuracy: 0.2463 - val_loss: 5.0984 - val_sparse_categorical_accuracy: 0.2247\n",
      "Epoch 44/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.6057 - sparse_categorical_accuracy: 0.2416\n",
      "Epoch 00044: saving model to ./models/model-44.hdf5\n",
      "242/242 [==============================] - 65s 269ms/step - loss: 4.6049 - sparse_categorical_accuracy: 0.2416 - val_loss: 5.0827 - val_sparse_categorical_accuracy: 0.2243\n",
      "Epoch 45/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.5446 - sparse_categorical_accuracy: 0.2458\n",
      "Epoch 00045: saving model to ./models/model-45.hdf5\n",
      "242/242 [==============================] - 64s 265ms/step - loss: 4.5438 - sparse_categorical_accuracy: 0.2458 - val_loss: 5.2938 - val_sparse_categorical_accuracy: 0.2148\n",
      "Epoch 46/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.4279 - sparse_categorical_accuracy: 0.2513\n",
      "Epoch 00046: saving model to ./models/model-46.hdf5\n",
      "242/242 [==============================] - 66s 273ms/step - loss: 4.4274 - sparse_categorical_accuracy: 0.2513 - val_loss: 5.1069 - val_sparse_categorical_accuracy: 0.2241\n",
      "Epoch 47/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.4362 - sparse_categorical_accuracy: 0.2522\n",
      "Epoch 00047: saving model to ./models/model-47.hdf5\n",
      "242/242 [==============================] - 67s 279ms/step - loss: 4.4355 - sparse_categorical_accuracy: 0.2523 - val_loss: 5.0849 - val_sparse_categorical_accuracy: 0.2274\n",
      "Epoch 48/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.3876 - sparse_categorical_accuracy: 0.2546\n",
      "Epoch 00048: saving model to ./models/model-48.hdf5\n",
      "242/242 [==============================] - 67s 276ms/step - loss: 4.3870 - sparse_categorical_accuracy: 0.2546 - val_loss: 5.0683 - val_sparse_categorical_accuracy: 0.2302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.4999 - sparse_categorical_accuracy: 0.2486\n",
      "Epoch 00049: saving model to ./models/model-49.hdf5\n",
      "242/242 [==============================] - 66s 274ms/step - loss: 4.4988 - sparse_categorical_accuracy: 0.2487 - val_loss: 5.3309 - val_sparse_categorical_accuracy: 0.2126\n",
      "Epoch 50/50\n",
      "241/242 [============================>.] - ETA: 0s - loss: 4.3420 - sparse_categorical_accuracy: 0.2579\n",
      "Epoch 00050: saving model to ./models/model-50.hdf5\n",
      "242/242 [==============================] - 67s 275ms/step - loss: 4.3414 - sparse_categorical_accuracy: 0.2580 - val_loss: 5.1095 - val_sparse_categorical_accuracy: 0.2263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215e703da90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./models/model-{epoch:02d}.hdf5', verbose=1)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./logs',\n",
    "    histogram_freq=1, batch_size=TRAIN_BATCH_SIZE,\n",
    "    write_graph=True, write_grads=False, write_images=True,\n",
    "    embeddings_freq=0, embeddings_layer_names=None,\n",
    "    embeddings_metadata=None, embeddings_data=None, update_freq=500\n",
    "    )\n",
    "\n",
    "model.fit_generator(generator=gen_train_data.generate(),\n",
    "                    steps_per_epoch=len_train // (TRAIN_BATCH_SIZE * TRAIN_NUM_STEP),\n",
    "                    epochs=NUM_EPOCH, callbacks=[cp_callback, tb_callback],\n",
    "                    validation_data=gen_val_data.generate(),\n",
    "                    validation_steps=len_val // (TRAIN_BATCH_SIZE * TRAIN_NUM_STEP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Restore and Test\n",
    "As we saved model for each epoch, we can try to test the model by predicting words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 17:07:01.880927 10056 deprecation.py:506] From C:\\Users\\HP\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0925 17:07:01.881924 10056 deprecation.py:506] From C:\\Users\\HP\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0925 17:07:01.881924 10056 deprecation.py:506] From C:\\Users\\HP\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "VOCAB = './ptb.vocab'          # Vocabulary file\n",
    "# Project word to id\n",
    "with codecs.open(VOCAB, 'r', 'utf-8') as f_vocab:\n",
    "    vocab = [w.strip() for w in f_vocab.readlines()]\n",
    "word_to_id = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
    "reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
    "\n",
    "data_test = np.array(load_data(TEST_DATA))\n",
    "len_test = len(data_test)\n",
    "\n",
    "model = keras.models.load_model('./models/model-50.hdf5')\n",
    "dummy_iters = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, comparing with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Actual words: director of this british industrial conglomerate <eos> a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported <eos> the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said <eos> <unk> inc. the unit of new york-based <unk> corp. that makes kent cigarettes stopped using <unk> in its <unk> cigarette filters in N <eos> although preliminary findings were reported more \n",
      "Predicted words: director of the <unk> bank bank <eos> the <unk> of <unk> <unk> <unk> to <unk> the <unk> <unk> and been the <unk> of of the <eos> <eos> the <unk> of <unk> and to the <eos> than N N <eos> <eos> said <eos> the <unk> <unk> is is expected <unk> by a 's a <unk> of the the <unk> to the <eos> a of the the the <eos> this said <eos> the <unk> a <unk> of the york <unk> <unk> a it the <unk> and as the <unk> the <unk> <unk> <unk> <eos> the <eos> the the <unk> are n't to \n"
     ]
    }
   ],
   "source": [
    "example_training_generator = KerasBatchGenerator(data_train, TRAIN_NUM_STEP, 1, VOCAB_SIZE,\n",
    "                                                 skip_step=1)print(\"Training data:\")\n",
    "\n",
    "for i in range(dummy_iters):\n",
    "    dummy = next(example_training_generator.generate())\n",
    "\n",
    "num_predict = 100\n",
    "true_print_out = \"Actual words: \"\n",
    "pred_print_out = \"Predicted words: \"\n",
    "for i in range(num_predict):\n",
    "    data = next(example_training_generator.generate())\n",
    "    prediction = model.predict(data[0])\n",
    "    predict_word = np.argmax(prediction[:, TRAIN_NUM_STEP - 1, :])\n",
    "    true_print_out += reversed_dictionary[data_train[TRAIN_NUM_STEP + dummy_iters + i]] + \" \"\n",
    "    pred_print_out += reversed_dictionary[predict_word] + \" \"\n",
    "print(true_print_out)\n",
    "print(pred_print_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, comparing with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data:\n",
      "Actual words: futures <eos> the N stock specialist firms on the big board floor the buyers and sellers of last resort who were criticized after the N crash once again could n't handle the selling pressure <eos> big investment banks refused to step up to the plate to support the beleaguered floor traders by buying big blocks of stock traders say <eos> heavy selling of standard & poor 's 500-stock index futures in chicago <unk> beat stocks downward <eos> seven big board stocks ual amr bankamerica walt disney capital cities\\/abc philip morris and pacific telesis group stopped trading and never resumed <eos> \n",
      "Predicted words: the <eos> the company N market <unk> are the <unk> board 's trading dollar will the of the year is <unk> <unk> by the <unk> crash <eos> the are n't be the value <eos> <eos> the board managers are to be up with the <unk> <eos> <unk> the company <unk> <eos> <eos> the the investors of the prices said <eos> the trading the the & poor 's 500-stock index rose fell the and the up of in the years banks volume were rose rose corp. disney co. corp. inc. morris cos. other telesis group of $ for <unk> <unk> <eos> \n"
     ]
    }
   ],
   "source": [
    "example_testing_generator = KerasBatchGenerator(data_test, TRAIN_NUM_STEP, 1, VOCAB_SIZE,\n",
    "                                                skip_step=1)\n",
    "print(\"Testing data:\")\n",
    "for i in range(dummy_iters):\n",
    "    dummy = next(example_testing_generator.generate())\n",
    "\n",
    "num_predict = 100\n",
    "true_print_out = \"Actual words: \"\n",
    "pred_print_out = \"Predicted words: \"\n",
    "for i in range(num_predict):\n",
    "    data = next(example_testing_generator.generate())\n",
    "    prediction = model.predict(data[0])\n",
    "    predict_word = np.argmax(prediction[:, TRAIN_NUM_STEP - 1, :])\n",
    "    true_print_out += reversed_dictionary[data_test[TRAIN_NUM_STEP + dummy_iters + i]] + \" \"\n",
    "    pred_print_out += reversed_dictionary[predict_word] + \" \"\n",
    "print(true_print_out)\n",
    "print(pred_print_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tpgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
